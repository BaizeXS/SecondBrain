"""Chat service with document context support."""

import json
import logging
from collections.abc import AsyncGenerator
from datetime import datetime
from typing import Any
from uuid import uuid4

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.crud.conversation import crud_conversation
from app.crud.message import crud_message
from app.models.models import Document, User
from app.schemas.chat import (
    ChatCompletionRequest,
    ChatCompletionResponse,
    Choice,
    Role,
    Usage,
)
from app.schemas.conversations import ChatMode, MessageCreate
from app.services.ai_service import ai_service
from app.services.vector_service import vector_service

logger = logging.getLogger(__name__)


class ChatService:
    """èŠå¤©æœåŠ¡ç±»ï¼Œæ”¯æŒæ–‡æ¡£ä¸Šä¸‹æ–‡."""

    def __init__(self) -> None:
        """åˆå§‹åŒ–èŠå¤©æœåŠ¡."""
        pass

    async def create_completion_with_documents(
        self,
        db: AsyncSession,
        request: ChatCompletionRequest,
        user: User,
    ) -> ChatCompletionResponse | AsyncGenerator[str, None]:
        """åˆ›å»ºåŒ…å«æ–‡æ¡£ä¸Šä¸‹æ–‡çš„èŠå¤©å®Œæˆ."""
        try:
            # å°†Messageå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            messages: list[dict[str, Any]] = []
            for msg in request.messages:
                if isinstance(msg, dict):
                    messages.append(msg)
                else:
                    messages.append(msg.model_dump())

            # å¦‚æœæä¾›äº†æ–‡æ¡£IDï¼Œè·å–æ–‡æ¡£å†…å®¹
            if request.document_ids:
                logger.info(f"ğŸ” ChatServiceæ”¶åˆ°æ–‡æ¡£IDè¯·æ±‚: {request.document_ids}, user_id={user.id}")
                
                context = await self._get_documents_context(
                    db, request.document_ids, user.id
                )
                
                if context:
                    logger.info(f"âœ… è·å–åˆ°æ–‡æ¡£ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(context)} å­—ç¬¦")
                    
                    # åœ¨ç”¨æˆ·æ¶ˆæ¯å‰æ’å…¥æ–‡æ¡£ä¸Šä¸‹æ–‡
                    context_message = {
                        "role": "system",
                        "content": f"ä»¥ä¸‹æ˜¯ç›¸å…³æ–‡æ¡£å†…å®¹ï¼Œè¯·åŸºäºè¿™äº›å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n\n{context}"
                    }
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯çš„ä½ç½®
                    user_msg_index = next(
                        (i for i, msg in enumerate(messages) if msg.get("role") == "user"),
                        len(messages)
                    )
                    messages.insert(user_msg_index, context_message)
                    logger.info(f"ğŸ“ æ–‡æ¡£ä¸Šä¸‹æ–‡å·²æ’å…¥åˆ°æ¶ˆæ¯åˆ—è¡¨ï¼Œä½ç½®: {user_msg_index}")
                else:
                    logger.warning(f"âŒ æ— æ³•è·å–æ–‡æ¡£ä¸Šä¸‹æ–‡: document_ids={request.document_ids}")
                    
                    # è®°å½•è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                    logger.warning(f"ğŸ” è°ƒè¯•ä¿¡æ¯: user_id={user.id}, conversation_id={request.conversation_id}, space_id={request.space_id}")

            # å¦‚æœæœ‰å¯¹è¯IDï¼ŒåŠ è½½å†å²æ¶ˆæ¯
            if request.conversation_id:
                history = await self._get_conversation_history(
                    db, request.conversation_id, user.id
                )
                if history:
                    # åˆå¹¶å†å²æ¶ˆæ¯ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯åœ¨å‰ï¼‰
                    system_msgs = [m for m in messages if m.get("role") == "system"]
                    other_msgs = [m for m in messages if m.get("role") != "system"]
                    messages = system_msgs + history + other_msgs

            # å¦‚æœæ˜¯Spaceå†…çš„å¯¹è¯ï¼Œå¯èƒ½éœ€è¦å‘é‡æœç´¢ç›¸å…³å†…å®¹
            if request.space_id and not request.document_ids:
                # ä»æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æå–æŸ¥è¯¢
                user_query: str | None = None
                for msg_dict in reversed(messages):
                    if isinstance(msg_dict, dict) and msg_dict.get("role") == "user":
                        user_query = msg_dict.get("content", "")
                        break

                if user_query:
                    # å‘é‡æœç´¢ç›¸å…³æ–‡æ¡£
                    relevant_docs = await self._search_relevant_documents(
                        db, user_query, request.space_id, user.id
                    )
                    if relevant_docs:
                        context = self._format_documents_context(relevant_docs)
                        context_message = {
                            "role": "system",
                            "content": f"ä»¥ä¸‹æ˜¯Spaceä¸­çš„ç›¸å…³å†…å®¹ï¼š\n\n{context}"
                        }
                        # åœ¨ç”¨æˆ·æ¶ˆæ¯å‰æ’å…¥
                        user_msg_index = next(
                            (i for i, msg in enumerate(messages) if msg.get("role") == "user"),
                            len(messages)
                        )
                        messages.insert(user_msg_index, context_message)

            # ç¡®å®šèŠå¤©æ¨¡å¼
            mode = ChatMode.CHAT
            if request.mode:
                mode = ChatMode[request.mode.upper()]

            # è°ƒç”¨AIæœåŠ¡
            if request.stream:
                return self._stream_completion(
                    messages, request, mode, user, db
                )
            else:
                response = await ai_service.chat(
                    messages=messages,
                    mode=mode,
                    model=request.model,
                    temperature=request.temperature,
                    max_tokens=request.max_tokens,
                    user=user,
                )

                # ä¿å­˜æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                if request.conversation_id:
                    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶è½¬æ¢ä¸ºå­—å…¸
                    last_message = request.messages[-1]
                    if hasattr(last_message, 'model_dump'):
                        user_msg_dict = last_message.model_dump()
                    else:
                        user_msg_dict = dict(last_message) if not isinstance(last_message, dict) else last_message

                    await self._save_messages(
                        db,
                        request.conversation_id,
                        user_msg_dict,  # ç”¨æˆ·æ¶ˆæ¯
                        response,  # AIå“åº”
                        request.model,
                        request.document_ids
                    )

                # æ„å»ºå“åº”
                from app.schemas.chat import Message as ChatMessage
                return ChatCompletionResponse(
                    id=f"chatcmpl-{uuid4().hex[:8]}",
                    created=int(datetime.now().timestamp()),
                    model=request.model,
                    choices=[Choice(
                        index=0,
                        message=ChatMessage(role=Role.assistant, content=response),
                        finish_reason="stop"
                    )],
                    usage=Usage(
                        prompt_tokens=sum(len(m.get("content", "")) for m in messages) // 4,
                        completion_tokens=len(response) // 4,
                        total_tokens=(sum(len(m.get("content", "")) for m in messages) + len(response)) // 4
                    )
                )

        except Exception as e:
            logger.error(f"Chat completion error: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    async def _stream_completion(
        self,
        messages: list[dict[str, Any]],
        request: ChatCompletionRequest,
        mode: ChatMode,
        user: User,
        db: AsyncSession
    ) -> AsyncGenerator[str, None]:
        """æµå¼ç”ŸæˆèŠå¤©å“åº”."""
        try:
            response_content = ""
            chunk_id = f"chatcmpl-{uuid4().hex[:8]}"

            async for chunk in ai_service.stream_chat(
                messages=messages,
                mode=mode,
                model=request.model,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                user=user,
            ):
                response_content += chunk

                # æ„å»ºæµå¼å“åº”å—
                chunk_data = {
                    "id": chunk_id,
                    "object": "chat.completion.chunk",
                    "created": int(datetime.now().timestamp()),
                    "model": request.model,
                    "choices": [{
                        "index": 0,
                        "delta": {"content": chunk},
                        "finish_reason": None
                    }]
                }

                yield f"data: {json.dumps(chunk_data)}\n\n"

            # å‘é€ç»“æŸå—
            final_chunk = {
                "id": chunk_id,
                "object": "chat.completion.chunk",
                "created": int(datetime.now().timestamp()),
                "model": request.model,
                "choices": [{
                    "index": 0,
                    "delta": {},
                    "finish_reason": "stop"
                }]
            }
            yield f"data: {json.dumps(final_chunk)}\n\n"
            yield "data: [DONE]\n\n"

            # ä¿å­˜æ¶ˆæ¯
            if request.conversation_id and response_content:
                # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶è½¬æ¢ä¸ºå­—å…¸
                last_message = request.messages[-1]
                if hasattr(last_message, 'model_dump'):
                    user_msg_dict = last_message.model_dump()
                else:
                    user_msg_dict = dict(last_message) if not isinstance(last_message, dict) else last_message

                await self._save_messages(
                    db,
                    request.conversation_id,
                    user_msg_dict,
                    response_content,
                    request.model,
                    request.document_ids
                )

        except Exception as e:
            logger.error(f"Stream completion error: {str(e)}")
            error_chunk = {
                "error": {
                    "message": str(e),
                    "type": "internal_error",
                    "code": "stream_error"
                }
            }
            yield f"data: {json.dumps(error_chunk)}\n\n"

    async def _get_documents_context(
        self,
        db: AsyncSession,
        document_ids: list[int],
        user_id: int,
        max_length: int = 8000
    ) -> str | None:
        """è·å–æ–‡æ¡£å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡."""
        try:
            logger.info(f"ğŸ” è·å–æ–‡æ¡£ä¸Šä¸‹æ–‡: document_ids={document_ids}, user_id={user_id}")
            
            # æŸ¥è¯¢æ–‡æ¡£
            stmt = select(Document).where(
                Document.id.in_(document_ids),
                Document.user_id == user_id,
                Document.content.isnot(None)
            )
            result = await db.execute(stmt)
            documents = result.scalars().all()
            
            logger.info(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£")
            
            if not documents:
                # å†æ¬¡æŸ¥è¯¢æ‰€æœ‰æ–‡æ¡£ï¼ˆåŒ…æ‹¬contentä¸ºNoneçš„ï¼‰æ¥è°ƒè¯•
                stmt_debug = select(Document).where(
                    Document.id.in_(document_ids),
                    Document.user_id == user_id
                )
                result_debug = await db.execute(stmt_debug)
                all_docs = result_debug.scalars().all()
                
                logger.warning(f"ğŸ” è°ƒè¯•æŸ¥è¯¢: æ‰¾åˆ° {len(all_docs)} ä¸ªæ–‡æ¡£ï¼ˆåŒ…æ‹¬contentä¸ºNoneï¼‰")
                for doc in all_docs:
                    logger.warning(f"ğŸ“„ æ–‡æ¡£ {doc.id}: filename={doc.filename}, content_length={len(doc.content) if doc.content else 0}, content_is_none={doc.content is None}")
                
                return None

            # æ„å»ºä¸Šä¸‹æ–‡
            contexts = []
            total_length = 0

            for doc in documents:
                logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {doc.id}: filename={doc.filename}, content_length={len(doc.content) if doc.content else 0}")
                
                if doc.content:
                    doc_context = f"### æ–‡æ¡£ï¼š{doc.title or doc.filename}\n{doc.content}\n"

                    # æ£€æŸ¥é•¿åº¦é™åˆ¶
                    if total_length + len(doc_context) > max_length:
                        remaining = max_length - total_length
                        if remaining > 100:  # è‡³å°‘ä¿ç•™100å­—ç¬¦
                            doc_context = doc_context[:remaining] + "...\n"
                            contexts.append(doc_context)
                        break

                    contexts.append(doc_context)
                    total_length += len(doc_context)
                    logger.info(f"âœ… æ–‡æ¡£ {doc.id} å†…å®¹å·²æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(doc_context)}")
                else:
                    logger.warning(f"âš ï¸ æ–‡æ¡£ {doc.id} æ²¡æœ‰å†…å®¹")

            context_result = "\n".join(contexts) if contexts else None
            logger.info(f"ğŸ¯ æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context_result) if context_result else 0}")
            
            return context_result

        except Exception as e:
            logger.error(f"Error getting documents context: {str(e)}")
            return None

    async def _get_conversation_history(
        self,
        db: AsyncSession,
        conversation_id: int,
        user_id: int,
        limit: int = 20
    ) -> list[dict[str, Any]]:
        """è·å–å¯¹è¯å†å²."""
        try:
            # è·å–å¯¹è¯
            conversation = await crud_conversation.get(db, id=conversation_id)
            if not conversation or conversation.user_id != user_id:
                return []

            # è·å–å†å²æ¶ˆæ¯
            messages = await crud_message.get_by_conversation(
                db,
                conversation_id=conversation_id,
                limit=limit
            )

            # è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
            history = []
            for message in reversed(messages):  # æŒ‰æ—¶é—´é¡ºåº
                history.append({
                    "role": message.role,
                    "content": message.content
                })

            return history

        except Exception as e:
            logger.error(f"Error getting conversation history: {str(e)}")
            return []

    async def _search_relevant_documents(
        self,
        db: AsyncSession,
        query: str,
        space_id: int,
        user_id: int,
        limit: int = 3
    ) -> list[Document]:
        """æœç´¢ç›¸å…³æ–‡æ¡£."""
        try:
            # ä½¿ç”¨å‘é‡æœç´¢
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            filter_conditions = {
                "space_id": space_id,
                "user_id": user_id
            }

            search_results = await vector_service.search_documents(
                query=query,
                limit=limit,
                filter_conditions=filter_conditions
            )

            if not search_results:
                return []

            # è·å–æ–‡æ¡£ID
            doc_ids = [result["document_id"] for result in search_results]

            # æŸ¥è¯¢æ–‡æ¡£
            stmt = select(Document).where(
                Document.id.in_(doc_ids),
                Document.user_id == user_id
            )
            result = await db.execute(stmt)
            documents = result.scalars().all()

            # æŒ‰ç›¸å…³æ€§æ’åº
            doc_map = {doc.id: doc for doc in documents}
            sorted_docs = []
            for search_result in search_results:
                doc_id = search_result["document_id"]
                if doc_id in doc_map:
                    sorted_docs.append(doc_map[doc_id])

            return sorted_docs

        except AttributeError as e:
            # å‘é‡æœåŠ¡æœªåˆå§‹åŒ–æˆ–ä¸å¯ç”¨
            logger.warning(f"Vector service not available: {str(e)}")
            return []
        except Exception as e:
            logger.error(f"Error searching relevant documents: {str(e)}")
            return []

    def _format_documents_context(self, documents: list[Document]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹ä¸ºä¸Šä¸‹æ–‡."""
        contexts = []

        for doc in documents:
            if doc.content:
                # æˆªå–æ–‡æ¡£çš„å…³é”®éƒ¨åˆ†
                content_preview = doc.content[:1500]
                if len(doc.content) > 1500:
                    content_preview += "..."

                contexts.append(
                    f"**{doc.title or doc.filename}**\n{content_preview}"
                )

        return "\n\n---\n\n".join(contexts)

    async def _save_messages(
        self,
        db: AsyncSession,
        conversation_id: int,
        user_message: dict[str, Any],
        assistant_response: str,
        model: str,
        document_ids: list[int] | None = None
    ) -> None:
        """ä¿å­˜æ¶ˆæ¯åˆ°å¯¹è¯å†å²."""
        try:
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await crud_message.create(
                db,
                obj_in=MessageCreate(
                    conversation_id=conversation_id,
                    role=user_message.get("role", "user"),
                    content=user_message.get("content", ""),
                    model=None,
                    provider=None,
                    meta_data={"document_ids": document_ids} if document_ids else None,
                    attachments=None
                )
            )

            # ä¿å­˜åŠ©æ‰‹å“åº”
            await crud_message.create(
                db,
                obj_in=MessageCreate(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=assistant_response,
                    model=model,
                    provider=self._get_provider_from_model(model),
                    meta_data={"referenced_documents": document_ids} if document_ids else None,
                    attachments=None
                )
            )

            # æ›´æ–°å¯¹è¯çš„æ¶ˆæ¯è®¡æ•°
            conversation = await crud_conversation.get(db, id=conversation_id)
            if conversation:
                conversation.message_count += 2
                await db.commit()

        except Exception as e:
            logger.error(f"Error saving messages: {str(e)}")
            await db.rollback()

    def _get_provider_from_model(self, model: str) -> str:
        """ä»æ¨¡å‹åç§°æ¨æ–­æä¾›å•†."""
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯OpenRouteræ ¼å¼çš„æ¨¡å‹
        if "/" in model:
            # OpenRouteræ ¼å¼: provider/model
            parts = model.split("/", 1)
            if len(parts) == 2:
                provider = parts[0].lower()
                # æ˜ å°„å¸¸è§çš„OpenRouteræä¾›å•†åç§°
                provider_map = {
                    "openai": "openai",
                    "anthropic": "anthropic",
                    "google": "google",
                    "meta-llama": "meta",
                    "perplexity": "perplexity",
                    "deepseek": "deepseek",
                    "openrouter": "openrouter",
                }
                return provider_map.get(provider, provider)

        # å…¼å®¹æ—§çš„æ¨æ–­é€»è¾‘
        model_lower = model.lower()
        if "gpt" in model_lower:
            return "openai"
        elif "claude" in model_lower:
            return "anthropic"
        elif "gemini" in model_lower:
            return "google"
        elif "deepseek" in model_lower:
            return "deepseek"
        elif "llama" in model_lower or "sonar" in model_lower:
            return "perplexity"
        else:
            return "openrouter"  # é»˜è®¤ä½¿ç”¨OpenRouter

    async def regenerate_message(
        self,
        db: AsyncSession,
        conversation_id: int,
        message_id: int,
        user: User,
        model: str | None = None,
        temperature: float | None = None
    ) -> str:
        """é‡æ–°ç”ŸæˆæŒ‡å®šæ¶ˆæ¯."""
        try:
            # è·å–æ¶ˆæ¯
            message = await crud_message.get(db, id=message_id)
            if not message or message.conversation_id != conversation_id:
                raise ValueError("æ¶ˆæ¯ä¸å­˜åœ¨")

            # è·å–å¯¹è¯
            conversation = await crud_conversation.get(db, id=conversation_id)
            if not conversation or conversation.user_id != user.id:
                raise ValueError("æ— æƒè®¿é—®æ­¤å¯¹è¯")

            # è·å–è¯¥æ¶ˆæ¯ä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
            all_messages = await crud_message.get_by_conversation(
                db, conversation_id=conversation_id, limit=100
            )

            # æ„å»ºæ¶ˆæ¯å†å²ï¼ˆåˆ°ç›®æ ‡æ¶ˆæ¯çš„å‰ä¸€æ¡ä¸ºæ­¢ï¼‰
            messages: list[dict[str, Any]] = []
            for msg in reversed(all_messages):
                if msg.id == message_id:
                    break
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

            # ç¡®ä¿æœ‰ä¸Šä¸‹æ–‡
            if not messages:
                raise ValueError("æ²¡æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡æ¥é‡æ–°ç”Ÿæˆ")

            # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æˆ–åŸæ¨¡å‹
            use_model = model or message.model or conversation.model
            use_temperature = temperature if temperature is not None else 0.7

            # é‡æ–°ç”Ÿæˆ
            new_response = await ai_service.chat(
                messages=messages,
                model=use_model,
                temperature=use_temperature,
                user=user
            )

            # æ›´æ–°æ¶ˆæ¯å†…å®¹
            message.content = new_response
            message.model = use_model
            message.meta_data = message.meta_data or {}
            message.meta_data["regenerated"] = True
            message.meta_data["regenerated_at"] = datetime.now().isoformat()

            await db.commit()
            await db.refresh(message)

            return new_response

        except Exception as e:
            logger.error(f"Error regenerating message: {str(e)}")
            raise


# å…¨å±€èŠå¤©æœåŠ¡å®ä¾‹
chat_service = ChatService()
