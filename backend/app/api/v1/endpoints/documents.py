"""Document endpoints v2 - ä½¿ç”¨æœåŠ¡å±‚å’ŒCRUDå±‚çš„å®Œæ•´ç‰ˆæœ¬."""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any

from fastapi import (
    APIRouter,
    Depends,
    File,
    Form,
    HTTPException,
    Query,
    UploadFile,
    status,
)
from fastapi.responses import FileResponse
from sqlalchemy.ext.asyncio import AsyncSession

from app import crud
from app.core.auth import get_current_active_user
from app.core.config import settings
from app.core.database import get_db
from app.models.models import User
from app.schemas.documents import (
    DocumentListResponse,
    DocumentResponse,
    DocumentUpdate,
    SearchRequest,
    SearchResponse,
    SearchResult,
)
from app.schemas.web_import import (
    BatchURLImportRequest,
    URLAnalysisRequest,
    URLAnalysisResponse,
    URLImportRequest,
    URLImportResponse,
    WebSnapshotResponse,
)
from app.services import document_service

logger = logging.getLogger(__name__)
router = APIRouter()


@router.post(
    "/upload", response_model=DocumentResponse, status_code=status.HTTP_201_CREATED
)
async def upload_document(
    space_id: int = Form(..., description="ç©ºé—´ID"),
    file: UploadFile = File(..., description="è¦ä¸Šä¼ çš„æ–‡ä»¶"),
    title: str | None = Form(None, description="æ–‡æ¡£æ ‡é¢˜"),
    tags: str | None = Form(None, description="æ ‡ç­¾ï¼Œé€—å·åˆ†éš”"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> DocumentResponse:
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†ç©ºé—´."""
    # æ£€æŸ¥ç©ºé—´æƒé™
    space = await crud.crud_space.get(db, id=space_id)
    if not space:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç©ºé—´ä¸å­˜åœ¨",
        )

    if space.user_id != current_user.id:
        # æ£€æŸ¥åä½œæƒé™
        access = await crud.crud_space.get_user_access(
            db, space_id=space_id, user_id=current_user.id
        )
        if not access or not access.can_edit:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒåœ¨æ­¤ç©ºé—´ä¸Šä¼ æ–‡æ¡£",
            )

    # éªŒè¯æ–‡ä»¶å¹¶ä¿®æ­£MIMEç±»å‹
    detected_content_type = file.content_type
    
    # å¦‚æœæµè§ˆå™¨æ£€æµ‹å¤±è´¥æˆ–æ£€æµ‹ä¸ºgenericç±»å‹ï¼Œä½¿ç”¨æ–‡ä»¶æ‰©å±•åä¿®æ­£
    if not detected_content_type or detected_content_type in ["application/octet-stream", ""]:
        if file.filename:
            file_ext = Path(file.filename).suffix.lower()
            content_type_map = {
                ".pdf": "application/pdf",
                ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                ".doc": "application/msword",
                ".txt": "text/plain",
                ".md": "text/markdown",
                ".pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
                ".ppt": "application/vnd.ms-powerpoint",
                ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                ".xls": "application/vnd.ms-excel",
                ".csv": "text/csv",
                ".jpg": "image/jpeg",
                ".jpeg": "image/jpeg",
                ".png": "image/png",
                ".gif": "image/gif",
                ".webp": "image/webp",
            }
            corrected_type = content_type_map.get(file_ext)
            if corrected_type:
                logger.info(f"ğŸ”§ MIMEç±»å‹ä¿®æ­£: {detected_content_type} â†’ {corrected_type} (åŸºäºæ‰©å±•å {file_ext})")
                detected_content_type = corrected_type
    
    if not detected_content_type:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹",
        )

    if detected_content_type not in settings.ALLOWED_FILE_TYPES:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {detected_content_type}",
        )

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    try:
        content = await file.read()
    except Exception as e:
        logger.error(f"Failed to read file content: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {str(e)}",
        )

    # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
    if content is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼ˆNoneï¼‰",
        )

    file_size = len(content)

    if file_size > settings.max_file_size_bytes:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆ{settings.MAX_FILE_SIZE_MB}MBï¼‰",
        )

    if file_size == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶ä¸ºç©º",
        )

    # å¤„ç†æ ‡ç­¾
    tag_list: list[str] | None = None
    if tags:
        tag_list = [tag.strip() for tag in tags.split(",") if tag.strip()]

    try:
        # æ™ºèƒ½å¤„ç†æ–‡ä»¶å†…å®¹
        processed_content = None
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å†…å®¹æå–çš„æ–‡ä»¶ç±»å‹
        extraction_needed_types = [
            "application/pdf",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            "application/msword",
            "application/vnd.ms-powerpoint"
        ]
        
        logger.info(f"ğŸ” æ£€æŸ¥æ–‡ä»¶ç±»å‹: detected_content_type={detected_content_type}")
        logger.info(f"ğŸ“‹ éœ€è¦æå–å†…å®¹çš„ç±»å‹: {extraction_needed_types}")
        logger.info(f"ğŸ¯ æ˜¯å¦éœ€è¦å†…å®¹æå–: {detected_content_type in extraction_needed_types}")
        
        if detected_content_type in extraction_needed_types:
            # éœ€è¦å†…å®¹æå–çš„æ–‡ä»¶ç±»å‹ï¼Œä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶å¹¶ä½¿ç”¨create_document_from_file
            import tempfile
            import os
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp_file:
                tmp_file.write(content)
                tmp_file_path = Path(tmp_file.name)
            
            try:
                # ä½¿ç”¨å¢å¼ºçš„æ–‡æ¡£åˆ›å»ºæ–¹æ³•ï¼ˆåŒ…å«å†…å®¹æå–ï¼‰
                document = await document_service.create_document_from_file(
                    db,
                    space_id=space_id,
                    file_path=tmp_file_path,
                    user=current_user,
                    title=title or file.filename,
                    original_filename=file.filename,  # æ˜¾å¼ä¼ é€’åŸå§‹æ–‡ä»¶å
                )
                
                logger.info(f"âœ… æ–‡æ¡£å†…å®¹æå–æˆåŠŸ: {file.filename}, å†…å®¹é•¿åº¦: {len(document.content or '')} å­—ç¬¦")
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass
                    
        elif detected_content_type.startswith('text/') or detected_content_type in ['text/markdown', 'text/plain']:
            # å¤„ç†æ–‡æœ¬æ–‡ä»¶
            # ç¡®ä¿contentä¸ä¸ºç©ºä¸”æ˜¯bytesç±»å‹
            if content is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å¤„ç†æ–‡æœ¬æ–‡ä»¶",
                )
            
            if not isinstance(content, bytes):
                logger.error(f"Expected bytes content, got {type(content)}")
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"æ–‡ä»¶å†…å®¹ç±»å‹é”™è¯¯: æœŸæœ›bytesï¼Œå¾—åˆ°{type(content)}",
                )
            
            try:
                # å°è¯•UTF-8è§£ç 
                processed_content = content.decode("utf-8")
                logger.info("Successfully decoded file as UTF-8")
            except UnicodeDecodeError as e:
                logger.warning(f"UTF-8 decoding failed: {e}")
                try:
                    # å°è¯•å…¶ä»–å¸¸è§ç¼–ç 
                    import chardet
                    detected_encoding = chardet.detect(content)
                    encoding = detected_encoding.get('encoding', 'utf-8') if detected_encoding else 'utf-8'
                    processed_content = content.decode(encoding, errors="ignore")
                    logger.info(f"ğŸ”¤ æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : {encoding}")
                except Exception as e:
                    logger.warning(f"ç¼–ç æ£€æµ‹å¤±è´¥: {e}ï¼Œä½¿ç”¨UTF-8 ignore")
                    processed_content = content.decode("utf-8", errors="ignore")
            except Exception as e:
                logger.error(f"æ–‡æœ¬æ–‡ä»¶è§£ç å¤±è´¥: {e}")
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"æ–‡æœ¬æ–‡ä»¶è§£ç å¤±è´¥: {str(e)}",
                )
            
            # åˆ›å»ºæ–‡æœ¬æ–‡æ¡£
            document = await document_service.create_document(
                db,
                space_id=space_id,
                filename=file.filename or "æœªå‘½åæ–‡æ¡£",
                content=processed_content,
                content_type=detected_content_type,
                file_size=file_size,
                user=current_user,
            )
        else:
            # å…¶ä»–äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆå¦‚å›¾ç‰‡ï¼‰ï¼Œä¸éœ€è¦å†…å®¹æå–
            document = await document_service.create_document(
                db,
                space_id=space_id,
                filename=file.filename or "æœªå‘½åæ–‡æ¡£",
                content=None,
                content_type=detected_content_type,
                file_size=file_size,
                user=current_user,
            )

        # æ›´æ–°æ–‡æ¡£çš„æ ‡é¢˜å’Œæ ‡ç­¾
        if title or tag_list:
            update_data = {}
            if title:
                update_data["title"] = title
            if tag_list:
                update_data["tags"] = tag_list

            document = await crud.crud_document.update(
                db, db_obj=document, obj_in=update_data
            )

        return DocumentResponse.model_validate(document)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {str(e)}",
        ) from e


@router.get("/", response_model=DocumentListResponse)
async def get_documents(
    space_id: int | None = Query(None, description="ç©ºé—´ID"),
    skip: int = Query(0, ge=0, description="è·³è¿‡çš„è®°å½•æ•°"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›çš„è®°å½•æ•°"),
    search: str | None = Query(None, description="æœç´¢å…³é”®è¯"),
    processing_status: str | None = Query(None, description="å¤„ç†çŠ¶æ€"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> DocumentListResponse:
    """è·å–æ–‡æ¡£åˆ—è¡¨."""
    if space_id:
        # æ£€æŸ¥ç©ºé—´æƒé™
        space = await crud.crud_space.get(db, id=space_id)
        if not space:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ç©ºé—´ä¸å­˜åœ¨",
            )

        # æ£€æŸ¥è®¿é—®æƒé™
        if space.user_id != current_user.id and not space.is_public:
            access = await crud.crud_space.get_user_access(
                db, space_id=space_id, user_id=current_user.id
            )
            if not access:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="æ— æƒè®¿é—®æ­¤ç©ºé—´",
                )

        # è·å–ç©ºé—´æ–‡æ¡£
        if search:
            documents = await crud.crud_document.search(
                db, space_id=space_id, query=search, skip=skip, limit=limit
            )
        else:
            documents = await crud.crud_document.get_by_space(
                db, space_id=space_id, skip=skip, limit=limit, status=processing_status
            )
    else:
        # è·å–ç”¨æˆ·çš„æ‰€æœ‰æ–‡æ¡£
        documents = await crud.crud_document.get_user_documents(
            db, user_id=current_user.id, skip=skip, limit=limit
        )

        # åº”ç”¨æœç´¢ç­›é€‰
        if search:
            documents = [
                d
                for d in documents
                if search.lower() in (d.title or d.filename).lower()
                or (d.content and search.lower() in d.content.lower())
            ]

        if processing_status:
            documents = [
                d for d in documents if d.processing_status == processing_status
            ]

    # è·å–æ€»æ•°
    total = len(documents)

    return DocumentListResponse(
        documents=[DocumentResponse.model_validate(doc) for doc in documents],
        total=total,
        page=skip // limit + 1,
        page_size=limit,
        has_next=total > skip + limit,
    )


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> DocumentResponse:
    """è·å–æ–‡æ¡£è¯¦æƒ…."""
    document = await document_service.get_document_by_id(db, document_id, current_user)

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®",
        )

    return DocumentResponse.model_validate(document)


@router.put("/{document_id}", response_model=DocumentResponse)
async def update_document(
    document_id: int,
    document_data: DocumentUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> DocumentResponse:
    """æ›´æ–°æ–‡æ¡£ä¿¡æ¯."""
    # è·å–æ–‡æ¡£
    document = await document_service.get_document_by_id(db, document_id, current_user)

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®",
        )

    # æ£€æŸ¥ç¼–è¾‘æƒé™
    space = await crud.crud_space.get(db, id=document.space_id)
    if space and space.user_id != current_user.id:
        access = await crud.crud_space.get_user_access(
            db, space_id=document.space_id, user_id=current_user.id
        )
        if not access or not access.can_edit:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒç¼–è¾‘æ­¤æ–‡æ¡£",
            )

    # æ›´æ–°æ–‡æ¡£
    try:
        updated_document = await crud.crud_document.update(
            db, db_obj=document, obj_in=document_data
        )
        return DocumentResponse.model_validate(updated_document)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ›´æ–°æ–‡æ¡£å¤±è´¥: {str(e)}",
        ) from e


@router.delete("/{document_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> None:
    """åˆ é™¤æ–‡æ¡£."""
    # è·å–æ–‡æ¡£
    document = await document_service.get_document_by_id(db, document_id, current_user)

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®",
        )

    # æ£€æŸ¥åˆ é™¤æƒé™
    space = await crud.crud_space.get(db, id=document.space_id)
    if space and space.user_id != current_user.id:
        access = await crud.crud_space.get_user_access(
            db, space_id=document.space_id, user_id=current_user.id
        )
        if not access or not access.can_delete:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒåˆ é™¤æ­¤æ–‡æ¡£",
            )

    # åˆ é™¤æ–‡æ¡£
    try:
        await document_service.delete_document(db, document)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}",
        ) from e


@router.post("/{document_id}/download")
async def download_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> FileResponse:
    """ä¸‹è½½æ–‡æ¡£æ–‡ä»¶."""
    # è·å–æ–‡æ¡£
    document = await document_service.get_document_by_id(db, document_id, current_user)

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®",
        )

    # æ³¨æ„ï¼šåœ¨ç®€åŒ–ç‰ˆæœ¬ä¸­ï¼Œæ–‡ä»¶å†…å®¹å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä»æ–‡ä»¶ç³»ç»Ÿæˆ–å¯¹è±¡å­˜å‚¨ä¸­è¯»å–
    if not document.content:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£å†…å®¹ä¸å­˜åœ¨",
        )

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è¿”å›
    import tempfile

    with tempfile.NamedTemporaryFile(
        mode="w", delete=False, suffix=f"_{document.filename}"
    ) as tmp:
        tmp.write(document.content)
        tmp_path = tmp.name

    return FileResponse(
        path=tmp_path,
        filename=document.filename,
        media_type=document.content_type,
    )


@router.get("/{document_id}/preview")
async def get_document_preview(
    document_id: int,
    page: int | None = Query(None, ge=1, description="PDFé¡µç "),
    format: str = Query("html", description="é¢„è§ˆæ ¼å¼: html/text/json"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> dict[str, Any]:
    """è·å–æ–‡æ¡£é¢„è§ˆå†…å®¹."""
    # è·å–æ–‡æ¡£
    document = await crud.crud_document.get(db, id=document_id)
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨",
        )

    # æ£€æŸ¥æƒé™
    if document.user_id != current_user.id:
        # æ£€æŸ¥ç©ºé—´æƒé™
        if document.space_id:
            space = await crud.crud_space.get(db, id=document.space_id)
            if not space or (not space.is_public and space.user_id != current_user.id):
                # æ£€æŸ¥åä½œæƒé™
                access = await crud.crud_space.get_user_access(
                    db, space_id=document.space_id, user_id=current_user.id
                )
                if not access:
                    raise HTTPException(
                        status_code=status.HTTP_403_FORBIDDEN,
                        detail="æ— æƒè®¿é—®æ­¤æ–‡æ¡£",
                    )

    # æ ¹æ®æ–‡æ¡£ç±»å‹è¿”å›é¢„è§ˆ
    if document.content_type and "pdf" in document.content_type.lower():
        # PDFæ–‡æ¡£
        return {
            "type": "pdf",
            "filename": document.filename,
            "title": document.title,
            "file_url": document.file_url
            or f"/api/v1/documents/{document_id}/download",
            "page_count": document.meta_data.get("page_count")
            if document.meta_data
            else None,
            "current_page": page,
            "content": document.content if page == 1 else None,  # ç¬¬ä¸€é¡µè¿”å›æå–çš„æ–‡æœ¬
        }
    elif document.content_type and any(
        img in document.content_type.lower()
        for img in ["image", "jpg", "jpeg", "png", "gif"]
    ):
        # å›¾ç‰‡æ–‡æ¡£
        return {
            "type": "image",
            "filename": document.filename,
            "title": document.title,
            "file_url": document.file_url
            or f"/api/v1/documents/{document_id}/download",
            "width": document.meta_data.get("width") if document.meta_data else None,
            "height": document.meta_data.get("height") if document.meta_data else None,
        }
    elif document.content:
        # æ–‡æœ¬ç±»æ–‡æ¡£
        content = document.content

        # æ ¹æ®æ ¼å¼è¿”å›
        if format == "html":
            # ç®€å•çš„Markdownåˆ°HTMLè½¬æ¢
            try:
                import markdown  # type: ignore[import-untyped]

                html_content = markdown.markdown(
                    content, extensions=["extra", "codehilite"]
                )
            except ImportError:
                html_content = f"<pre>{content}</pre>"

            return {
                "type": "text",
                "format": "html",
                "filename": document.filename,
                "title": document.title,
                "content": html_content,
                "language": document.language,
            }
        elif format == "json":
            return {
                "type": "text",
                "format": "json",
                "filename": document.filename,
                "title": document.title,
                "content": content,
                "summary": document.summary,
                "language": document.language,
                "metadata": document.meta_data,
            }
        else:  # text
            return {
                "type": "text",
                "format": "text",
                "filename": document.filename,
                "title": document.title,
                "content": content,
                "language": document.language,
            }
    else:
        # äºŒè¿›åˆ¶æ–‡ä»¶æˆ–æœªå¤„ç†çš„æ–‡æ¡£
        return {
            "type": "binary",
            "filename": document.filename,
            "title": document.title,
            "file_url": document.file_url
            or f"/api/v1/documents/{document_id}/download",
            "content_type": document.content_type,
            "file_size": document.file_size,
            "message": "æ­¤æ–‡æ¡£ç±»å‹ä¸æ”¯æŒé¢„è§ˆï¼Œè¯·ä¸‹è½½æŸ¥çœ‹",
        }


@router.get("/{document_id}/content")
async def get_document_content(
    document_id: int,
    start: int = Query(0, ge=0, description="èµ·å§‹ä½ç½®"),
    length: int = Query(5000, ge=100, le=50000, description="å†…å®¹é•¿åº¦"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> dict[str, Any]:
    """è·å–æ–‡æ¡£çš„æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒåˆ†é¡µï¼‰."""
    # è·å–æ–‡æ¡£
    document = await crud.crud_document.get(db, id=document_id)
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨",
        )

    # æ£€æŸ¥æƒé™ï¼ˆåŒä¸Šï¼‰
    if document.user_id != current_user.id:
        if document.space_id:
            space = await crud.crud_space.get(db, id=document.space_id)
            if not space or (not space.is_public and space.user_id != current_user.id):
                access = await crud.crud_space.get_user_access(
                    db, space_id=document.space_id, user_id=current_user.id
                )
                if not access:
                    raise HTTPException(
                        status_code=status.HTTP_403_FORBIDDEN,
                        detail="æ— æƒè®¿é—®æ­¤æ–‡æ¡£",
                    )

    if not document.content:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ­¤æ–‡æ¡£æ²¡æœ‰å¯ç”¨çš„æ–‡æœ¬å†…å®¹",
        )

    # è·å–å†…å®¹ç‰‡æ®µ
    total_length = len(document.content)
    end = min(start + length, total_length)
    content_slice = document.content[start:end]

    return {
        "document_id": document_id,
        "title": document.title,
        "content": content_slice,
        "start": start,
        "end": end,
        "total_length": total_length,
        "has_more": end < total_length,
    }


@router.post(
    "/import-url", response_model=URLImportResponse, status_code=status.HTTP_201_CREATED
)
async def import_url(
    import_data: URLImportRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> URLImportResponse:
    """ä»URLå¯¼å…¥ç½‘é¡µå†…å®¹åˆ°çŸ¥è¯†ç©ºé—´."""
    # æ£€æŸ¥ç©ºé—´æƒé™
    space = await crud.crud_space.get(db, id=import_data.space_id)
    if not space:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç©ºé—´ä¸å­˜åœ¨",
        )

    if space.user_id != current_user.id:
        # æ£€æŸ¥åä½œæƒé™
        access = await crud.crud_space.get_user_access(
            db, space_id=import_data.space_id, user_id=current_user.id
        )
        if not access or not access.can_edit:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒåœ¨æ­¤ç©ºé—´å¯¼å…¥æ–‡æ¡£",
            )

    # å¯¼å…¥ç½‘é¡µ
    result = await document_service.import_from_url(
        db,
        url=str(import_data.url),
        space_id=import_data.space_id,
        user=current_user,
        title=import_data.title,
        tags=import_data.tags,
        save_snapshot=import_data.save_snapshot,
    )

    if result["status"] == "error":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=result.get("error", "å¯¼å…¥å¤±è´¥"),
        )

    # è·å–æ–‡æ¡£è¯¦æƒ…
    document = await crud.crud_document.get(db, id=result["document_id"])
    if not document:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="æ–‡æ¡£åˆ›å»ºå¤±è´¥",
        )

    return URLImportResponse(
        document_id=document.id,
        url=str(import_data.url),
        title=document.title or "æœªå‘½åæ–‡æ¡£",
        status="success",
        metadata=result.get("metadata"),
        created_at=document.created_at,
    )


@router.post("/batch-import-urls", response_model=list[URLImportResponse])
async def batch_import_urls(
    import_data: BatchURLImportRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> list[URLImportResponse]:
    """æ‰¹é‡ä»URLå¯¼å…¥ç½‘é¡µå†…å®¹."""
    # æ£€æŸ¥ç©ºé—´æƒé™ï¼ˆåŒä¸Šï¼‰
    space = await crud.crud_space.get(db, id=import_data.space_id)
    if not space:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç©ºé—´ä¸å­˜åœ¨",
        )

    if space.user_id != current_user.id:
        access = await crud.crud_space.get_user_access(
            db, space_id=import_data.space_id, user_id=current_user.id
        )
        if not access or not access.can_edit:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒåœ¨æ­¤ç©ºé—´å¯¼å…¥æ–‡æ¡£",
            )

    # æ‰¹é‡å¯¼å…¥
    results = await document_service.batch_import_urls(
        db,
        urls=[str(url) for url in import_data.urls],
        space_id=import_data.space_id,
        user=current_user,
        tags=import_data.tags,
        save_snapshot=import_data.save_snapshot,
    )

    # æ„å»ºå“åº”
    responses = []
    for result in results:
        if result["status"] == "success":
            document = await crud.crud_document.get(db, id=result["document_id"])
            if document:
                responses.append(
                    URLImportResponse(
                        document_id=document.id,
                        url=result["url"],
                        title=document.title or "æœªå‘½åæ–‡æ¡£",
                        status="success",
                        metadata=result.get("metadata"),
                        created_at=document.created_at,
                    )
                )
        else:
            responses.append(
                URLImportResponse(
                    document_id=0,
                    url=result["url"],
                    title="",
                    status="error",
                    error=result.get("error"),
                    created_at=datetime.now(),
                )
            )

    return responses


@router.get("/{document_id}/snapshot", response_model=WebSnapshotResponse)
async def get_web_snapshot(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> WebSnapshotResponse:
    """è·å–ç½‘é¡µæ–‡æ¡£çš„å¿«ç…§."""
    snapshot = await document_service.get_web_snapshot(db, document_id, current_user)

    if not snapshot:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¿«ç…§ä¸å­˜åœ¨æˆ–è¯¥æ–‡æ¡£ä¸æ˜¯ç½‘é¡µæ–‡æ¡£",
        )

    return WebSnapshotResponse(**snapshot)


@router.post("/analyze-url", response_model=URLAnalysisResponse)
async def analyze_url(
    analysis_data: URLAnalysisRequest,
    current_user: User = Depends(get_current_active_user),  # noqa: ARG001
) -> URLAnalysisResponse:
    """åˆ†æURLå†…å®¹ï¼ˆä¸ä¿å­˜ï¼‰."""
    analysis = await document_service.analyze_url(str(analysis_data.url))

    if not analysis.get("can_import"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=analysis.get("error", "æ— æ³•åˆ†æè¯¥URL"),
        )

    return URLAnalysisResponse(**analysis)


@router.post("/search", response_model=SearchResponse)
async def search_documents(
    search_request: SearchRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> SearchResponse:
    """æœç´¢æ–‡æ¡£."""
    # å¦‚æœæŒ‡å®šäº†space_idï¼Œæ£€æŸ¥æƒé™
    if search_request.space_id:
        space = await crud.crud_space.get(db, id=search_request.space_id)
        if not space:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ç©ºé—´ä¸å­˜åœ¨",
            )

        # æ£€æŸ¥è®¿é—®æƒé™
        if space.user_id != current_user.id and not space.is_public:
            access = await crud.crud_space.get_user_access(
                db, space_id=search_request.space_id, user_id=current_user.id
            )
            if not access:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="æ— æƒè®¿é—®æ­¤ç©ºé—´",
                )

    # æ‰§è¡Œæœç´¢
    import time

    start_time = time.time()

    # ç®€å•çš„å…³é”®è¯æœç´¢å®ç°
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨ vector_service è¿›è¡Œå‘é‡æœç´¢
    query = search_request.query.lower()
    all_documents = await crud.crud_document.get_multi(db, limit=1000)

    # è¿‡æ»¤ç”¨æˆ·å¯è®¿é—®çš„æ–‡æ¡£
    accessible_docs = []
    for doc in all_documents:
        # æ£€æŸ¥æ–‡æ¡£æƒé™
        if doc.user_id == current_user.id:
            accessible_docs.append(doc)
        elif doc.space_id:
            space = await crud.crud_space.get(db, id=doc.space_id)
            if space and (space.is_public or space.user_id == current_user.id):
                accessible_docs.append(doc)
            else:
                # æ£€æŸ¥åä½œæƒé™
                access = await crud.crud_space.get_user_access(
                    db, space_id=doc.space_id, user_id=current_user.id
                )
                if access:
                    accessible_docs.append(doc)

    # å¦‚æœæŒ‡å®šäº†space_idï¼Œåªæœç´¢è¯¥ç©ºé—´çš„æ–‡æ¡£
    if search_request.space_id:
        accessible_docs = [
            doc for doc in accessible_docs if doc.space_id == search_request.space_id
        ]

    # æ‰§è¡Œæœç´¢
    results = []
    for doc in accessible_docs:
        score = 0.0
        highlights = {}

        # æœç´¢æ ‡é¢˜
        if doc.title and query in doc.title.lower():
            score += 2.0
            highlights["title"] = [doc.title]

        # æœç´¢æ–‡ä»¶å
        if query in doc.filename.lower():
            score += 1.5
            highlights["filename"] = [doc.filename]

        # æœç´¢å†…å®¹
        if doc.content and query in doc.content.lower():
            score += 1.0
            # æå–åŒ…å«æŸ¥è¯¢è¯çš„ç‰‡æ®µ
            content_lower = doc.content.lower()
            idx = content_lower.find(query)
            if idx != -1:
                start = max(0, idx - 50)
                end = min(len(doc.content), idx + len(query) + 50)
                snippet = doc.content[start:end]
                if start > 0:
                    snippet = "..." + snippet
                if end < len(doc.content):
                    snippet = snippet + "..."
                highlights["content"] = [snippet]

        # æœç´¢æ ‡ç­¾
        if doc.tags:
            for tag in doc.tags:
                if query in tag.lower():
                    score += 0.5
                    highlights["tags"] = doc.tags
                    break

        if score > 0:
            results.append(
                SearchResult(
                    document_id=doc.id,
                    title=doc.title or doc.filename,
                    snippet=highlights.get("content", [""])[0]
                    if "content" in highlights
                    else doc.summary or "",
                    score=score,
                    highlight=highlights,
                )
            )

    # æŒ‰åˆ†æ•°æ’åº
    results.sort(key=lambda x: x.score, reverse=True)

    # é™åˆ¶ç»“æœæ•°é‡
    results = results[: search_request.limit]

    search_time = time.time() - start_time

    return SearchResponse(
        results=results,
        total=len(results),
        query=search_request.query,
        search_time=search_time,
    )
